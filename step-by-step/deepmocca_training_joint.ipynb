{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae58d66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA_VISIBLE_DEVICES=0,1\n",
    "# CUDA_LAUNCH_BLOCKING=1\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import rdflib as rl\n",
    "import torch\n",
    "import torchtuples as tt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pycox.models import CoxPH\n",
    "from pycox.evaluation import EvalSurv\n",
    "from torch_geometric.data import Data, DataLoader, Batch\n",
    "from torch_geometric.nn import GCNConv, SAGEConv, GraphConv, SAGPooling, GENConv, GATConv\n",
    "from torch_geometric.nn import global_max_pool as gmp\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "import click as ck\n",
    "import gzip\n",
    "import pickle\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "import pandas as pd\n",
    "import random\n",
    "# from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123a8e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually categorized cancer subtypes\n",
    "CANCER_SUBTYPES = [\n",
    "    [0,12,7,14,4,1,6,2,3],\n",
    "    [4],\n",
    "    [5,4,14,6],\n",
    "    [6,4,12,7],\n",
    "    [4],\n",
    "    [6,4,12,7],\n",
    "    [8],\n",
    "    [6,4,12],\n",
    "    [9],\n",
    "    [6],\n",
    "    [4],\n",
    "    [4],\n",
    "    [4],\n",
    "    [10],\n",
    "    [9],\n",
    "    [4],\n",
    "    [4,11,12],\n",
    "    [6],\n",
    "    [13],\n",
    "    [12],\n",
    "    [0,4,12,14],\n",
    "    [15],\n",
    "    [4,0,12],\n",
    "    [4,12],\n",
    "    [16,17,18,19,20],\n",
    "    [20],\n",
    "    [4,12],\n",
    "    [22],\n",
    "    [4,14],\n",
    "    [23],\n",
    "    [4,12,14],\n",
    "    [24],\n",
    "    [21]\n",
    "]\n",
    "\n",
    "CELL_TYPES = [\n",
    "    0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 3, 0, 0, 4, 2, 0,\n",
    "    0, 0, 5, 0, 0, 6, 0, 0, 7, 8, 0, 9, 0, 0, 0, 0,\n",
    "    8]\n",
    "\n",
    "cancer_types = [\n",
    "    \"TCGA-ACC\", \"TCGA-BLCA\", \"TCGA-BRCA\", \"TCGA-CESC\",\n",
    "    \"TCGA-CHOL\", \"TCGA-COAD\", \"TCGA-DLBC\", \"TCGA-ESCA\",\n",
    "    \"TCGA-GBM\", \"TCGA-HNSC\", \"TCGA-KICH\", \"TCGA-KIRC\",\n",
    "    \"TCGA-KIRP\", \"TCGA-LAML\",\"TCGA-LGG\",\"TCGA-LIHC\",\n",
    "    \"TCGA-LUAD\",\"TCGA-LUSC\",\"TCGA-MESO\",\"TCGA-OV\",\n",
    "    \"TCGA-PAAD\",\"TCGA-PCPG\",\"TCGA-PRAD\",\"TCGA-READ\",\n",
    "    \"TCGA-SARC\",\"TCGA-SKCM\",\"TCGA-STAD\",\"TCGA-TGCT\",\n",
    "    \"TCGA-THCA\",\"TCGA-THYM\",\"TCGA-UCEC\",\"TCGA-UCS\",\"TCGA-UVM\"]\n",
    "\n",
    "\n",
    "# cancer = str(sys.argv[1])\n",
    "cancer = 'TCGA-ACC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7303a578",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# def setup(rank, world_size):\n",
    "#     os.environ['MASTER_ADDR'] = 'localhost'\n",
    "#     os.environ['MASTER_PORT'] = '12355'\n",
    "\n",
    "#     # initialize the process group\n",
    "#     dist.init_process_group(\"gloo\", rank=rank, world_size=world_size)\n",
    "\n",
    "# def cleanup():\n",
    "#     dist.destroy_process_group()\n",
    "\n",
    "# torch.cuda.set_device(device)\n",
    "\n",
    "proteins_df = pd.read_pickle('data/proteins.pkl')\n",
    "interactions_df = pd.read_pickle('data/interactions.pkl')\n",
    "proteins = {row.proteins: row.ids for row in proteins_df.itertuples()}\n",
    "edge_index = [interactions_df['protein1'].values, interactions_df['protein2'].values]\n",
    "edge_index = torch.LongTensor(edge_index).to(device)\n",
    "\n",
    "# proteins, edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5f9957",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNet(nn.Module):\n",
    "    def __init__(self, num_nodes, edge_index):\n",
    "        super(MyNet, self).__init__()\n",
    "        self.num_nodes = num_nodes\n",
    "        self.edge_index = edge_index\n",
    "        self.conv1 = GraphConv(6, 6)\n",
    "        self.pool1 = SAGPooling(6, ratio=0.1, GNN=GraphConv)\n",
    "        self.fc1 = nn.Linear(10314, 1024, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(1024)\n",
    "        self.dropout1 = nn.Dropout(0.1)\n",
    "        self.fc2 = nn.Linear(1024, 512, bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(512)\n",
    "        self.dropout2 = nn.Dropout(0.1)\n",
    "        self.fc3 = nn.Linear(512, 1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm1d(1)\n",
    "        self.dropout3 = nn.Dropout(0.1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.batches = {}\n",
    "\n",
    "    def forward(self, data):\n",
    "#         print(data.shape)\n",
    "        batch_size = data.shape[0]\n",
    "        x = data[:, :self.num_nodes * 6]\n",
    "        x = x.reshape(batch_size, self.num_nodes, 6)\n",
    "        l = []\n",
    "        for i in range(batch_size):\n",
    "            l.append(Data(x=x[i], edge_index=self.edge_index))\n",
    "        batch = Batch.from_data_list(l).to(device)\n",
    "        x = x.reshape(-1, 6)\n",
    "        x = F.relu(self.conv1(x=x, edge_index=batch.edge_index))\n",
    "        x, edge_index, _, batch, perm, score = self.pool1(\n",
    "            x, batch.edge_index, None, batch.batch)\n",
    "        x = x.view(batch_size, -1)\n",
    "        # print(x.shape)\n",
    "        x = self.dropout1(self.bn1(torch.relu(self.fc1(x))))\n",
    "        x = self.dropout2(self.bn2(torch.relu(self.fc2(x))))\n",
    "        x = self.dropout3(self.bn3(self.fc3(x)))\n",
    "        return x\n",
    "    \n",
    "net = MyNet(len(proteins), edge_index).to(device)\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cdcb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data, minx=None, maxx=None):\n",
    "    if minx is None:\n",
    "        minx = np.min(data)\n",
    "        maxx = np.max(data)\n",
    "    if minx == maxx:\n",
    "        return data\n",
    "    return (data - minx) / (maxx - minx)\n",
    "        \n",
    "def normalize_by_row(data):\n",
    "    for i in range(data.shape[0]):\n",
    "        data[i, :] = normalize(data[i, :])\n",
    "    return data\n",
    "\n",
    "def normalize_by_column(data):\n",
    "    for i in range(data.shape[1]):\n",
    "        data[:, i] = normalize(data[:, i])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bad176c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_ = 0.01\n",
    "pat_ = 10\n",
    "cancer_combined = pd.DataFrame()\n",
    "for i, cancer__type in enumerate(cancer_types):\n",
    "    if cancer__type != cancer:\n",
    "        df = pd.read_pickle(f'preprocessing_codes/{cancer__type}.pkl')\n",
    "#         print(df.shape)\n",
    "        cancer_combined = pd.concat([cancer_combined, df], ignore_index=True)\n",
    "# print(cancer_combined.shape)\n",
    "# print(\"Done 1\")\n",
    "val_dataset = cancer_combined.sample(frac =.2)\n",
    "\n",
    "val_labels_days = val_dataset['duration'].values\n",
    "val_labels_surv = val_dataset['survival'].values\n",
    "\n",
    "cancer_combined = cancer_combined.drop(val_dataset.index)\n",
    "\n",
    "dataset = np.stack(cancer_combined['features'].values).reshape(len(cancer_combined), -1)\n",
    "\n",
    "val_dataset = np.stack(val_dataset['features'].values).reshape(len(val_dataset), -1)\n",
    "\n",
    "# print('Validation shape = '+val_dataset.shape)\n",
    "\n",
    "in_features = dataset.shape[1]\n",
    "labels_days = cancer_combined['duration'].values\n",
    "labels_surv = cancer_combined['survival'].values\n",
    "\n",
    "df_test = pd.read_pickle(f'preprocessing_codes/{cancer}.pkl')\n",
    "\n",
    "test_labels_days = df_test['duration'].values\n",
    "test_labels_surv = df_test['survival'].values\n",
    "\n",
    "df_test = np.stack(df_test['features'].values).reshape(len(df_test), -1)\n",
    "\n",
    "# print(\"Done 2\")\n",
    "num_features = 6\n",
    "num_nodes = 17185\n",
    "\n",
    "del net\n",
    "torch.manual_seed(0)\n",
    "net = MyNet(len(proteins), edge_index).to(device)\n",
    "\n",
    "model = CoxPH(net, tt.optim.Adam(lr_))\n",
    "\n",
    "train_data = dataset\n",
    "\n",
    "train_data = train_data.reshape(-1, num_nodes, num_features)\n",
    "\n",
    "for i in range(num_features):\n",
    "    if i <= 5:\n",
    "        train_data[:, :, i] = normalize_by_row(train_data[:, :, i])\n",
    "    elif i > 5 and i <= 11:\n",
    "        train_data[:, :, i] = normalize_by_column(train_data[:, :, i])\n",
    "    else:\n",
    "        train_data[:, :, i] = normalize(train_data[:, :, i])\n",
    "\n",
    "train_data = train_data.reshape(-1, num_nodes * num_features)\n",
    "\n",
    "train_labels_days = labels_days\n",
    "train_labels_surv = labels_surv\n",
    "train_labels = (train_labels_days, train_labels_surv)\n",
    "# print(\"Done 3\")\n",
    "val_data = val_dataset\n",
    "val_data = val_data.reshape(-1, num_nodes, num_features)\n",
    "for i in range(num_features):\n",
    "    if i <= 5:\n",
    "        val_data[:, :, i] = normalize_by_row(val_data[:, :, i])\n",
    "    elif i > 5 and i <= 11:\n",
    "        val_data[:, :, i] = normalize_by_column(val_data[:, :, i])\n",
    "    else:\n",
    "        val_data[:, :, i] = normalize(val_data[:, :, i])\n",
    "\n",
    "val_data = val_data.reshape(-1, num_nodes * num_features)\n",
    "# print(\"Done 4\")\n",
    "test_data = df_test\n",
    "test_data = test_data.reshape(-1, num_nodes, num_features)\n",
    "for i in range(num_features):\n",
    "    if i <= 5:\n",
    "        test_data[:, :, i] = normalize_by_row(test_data[:, :, i])\n",
    "    elif i > 5 and i <= 11:\n",
    "        test_data[:, :, i] = normalize_by_column(test_data[:, :, i])\n",
    "    else:\n",
    "        test_data[:, :, i] = normalize(test_data[:, :, i])\n",
    "\n",
    "test_data = test_data.reshape(-1, num_nodes * num_features)\n",
    "# print(\"Done 5\")\n",
    "val_labels = (val_labels_days, val_labels_surv)\n",
    "\n",
    "# print(val_labels)\n",
    "# print('Training data', train_data.shape)\n",
    "# print('Validation data', val_data.shape)\n",
    "# print('Testing data', test_data.shape)\n",
    "callbacks = [tt.callbacks.EarlyStopping(patience=pat_)]\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "val = (val_data, val_labels)\n",
    "log = model.fit(\n",
    "    train_data, train_labels, batch_size, epochs, callbacks, verbose=True,\n",
    "    val_data=val,\n",
    "    val_batch_size=batch_size, shuffle=True)\n",
    "train = train_data, train_labels\n",
    "# Compute the evaluation measurements\n",
    "_ = model.compute_baseline_hazards(*train)\n",
    "surv = model.predict_surv_df(test_data)\n",
    "ev = EvalSurv(surv, test_labels_days, test_labels_surv)\n",
    "result = ev.concordance_td()\n",
    "\n",
    "print(cancer)\n",
    "print('lr = '+str(lr_))\n",
    "print('patience = '+str(pat_))\n",
    "print('normalization = row')\n",
    "print('Concordance', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0a27fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
