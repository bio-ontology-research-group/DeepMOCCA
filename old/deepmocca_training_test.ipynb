{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c10a1cd",
   "metadata": {},
   "source": [
    "# Training individual models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3810c031",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "390957cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA_VISIBLE_DEVICES=0,1\n",
    "# CUDA_LAUNCH_BLOCKING=1\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import rdflib as rl\n",
    "import torch\n",
    "import torchtuples as tt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pycox.models import CoxPH\n",
    "from pycox.evaluation import EvalSurv\n",
    "from torch_geometric.data import Data, DataLoader, Batch\n",
    "from torch_geometric.nn import GCNConv, SAGEConv, GraphConv, GENConv, GATConv\n",
    "from SAGPooling import SAGPooling\n",
    "from torch_geometric.nn import global_max_pool as gmp\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "import click as ck\n",
    "import gzip\n",
    "import pickle\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "import pandas as pd\n",
    "import random\n",
    "# from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0905770",
   "metadata": {},
   "source": [
    "## Constant variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "24a8d566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually categorized cancer subtypes\n",
    "CANCER_SUBTYPES = [\n",
    "    [0,12,7,14,4,1,6,2,3],\n",
    "    [4],\n",
    "    [5,4,14,6],\n",
    "    [6,4,12,7],\n",
    "    [4],\n",
    "    [6,4,12,7],\n",
    "    [8],\n",
    "    [6,4,12],\n",
    "    [9],\n",
    "    [6],\n",
    "    [4],\n",
    "    [4],\n",
    "    [4],\n",
    "    [10],\n",
    "    [9],\n",
    "    [4],\n",
    "    [4,11,12],\n",
    "    [6],\n",
    "    [13],\n",
    "    [12],\n",
    "    [0,4,12,14],\n",
    "    [15],\n",
    "    [4,0,12],\n",
    "    [4,12],\n",
    "    [16,17,18,19,20],\n",
    "    [20],\n",
    "    [4,12],\n",
    "    [22],\n",
    "    [4,14],\n",
    "    [23],\n",
    "    [4,12,14],\n",
    "    [24],\n",
    "    [21]\n",
    "]\n",
    "\n",
    "CELL_TYPES = [\n",
    "    0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 3, 0, 0, 4, 2, 0,\n",
    "    0, 0, 5, 0, 0, 6, 0, 0, 7, 8, 0, 9, 0, 0, 0, 0,\n",
    "    8]\n",
    "\n",
    "# cancer_types = [\n",
    "#     \"TCGA-ACC\", \"TCGA-BLCA\", \"TCGA-BRCA\", \"TCGA-CESC\",\n",
    "#     \"TCGA-CHOL\", \"TCGA-COAD\", \"TCGA-DLBC\", \"TCGA-ESCA\",\n",
    "#     \"TCGA-GBM\", \"TCGA-HNSC\", \"TCGA-KICH\", \"TCGA-KIRC\",\n",
    "#     \"TCGA-KIRP\", \"TCGA-LAML\",\"TCGA-LGG\",\"TCGA-LIHC\",\n",
    "#     \"TCGA-LUAD\",\"TCGA-LUSC\",\"TCGA-MESO\",\"TCGA-OV\",\n",
    "#     \"TCGA-PAAD\",\"TCGA-PCPG\",\"TCGA-PRAD\",\"TCGA-READ\",\n",
    "#     \"TCGA-SARC\",\"TCGA-SKCM\",\"TCGA-STAD\",\"TCGA-TGCT\",\n",
    "#     \"TCGA-THCA\",\"TCGA-THYM\",\"TCGA-UCEC\",\"TCGA-UCS\",\"TCGA-UVM\"]\n",
    "\n",
    "# cancer_types = [str(sys.argv[1])]\n",
    "\n",
    "cancer_types = ['TCGA-BRCA']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f1bd0f",
   "metadata": {},
   "source": [
    "## Load proteins and interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9a110f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# def setup(rank, world_size):\n",
    "#     os.environ['MASTER_ADDR'] = 'localhost'\n",
    "#     os.environ['MASTER_PORT'] = '12355'\n",
    "\n",
    "#     # initialize the process group\n",
    "#     dist.init_process_group(\"gloo\", rank=rank, world_size=world_size)\n",
    "\n",
    "# def cleanup():\n",
    "#     dist.destroy_process_group()\n",
    "\n",
    "# torch.cuda.set_device(device)\n",
    "\n",
    "proteins_df = pd.read_pickle('data/proteins_700.pkl')\n",
    "# interactions_df = pd.read_pickle('data/interactions_700.pkl')\n",
    "interactions_df = pd.read_csv('pr.tsv', header=None, sep='\\t')\n",
    "interactions_df.columns = ['protein1','protein2']\n",
    "proteins = {row.proteins: row.ids for row in proteins_df.itertuples()}\n",
    "edge_index = [interactions_df['protein1'].values, interactions_df['protein2'].values]\n",
    "edge_index = torch.LongTensor(edge_index).to(device)\n",
    "\n",
    "# edge_index = torch.empty_like(edge_index)\n",
    "# proteins, edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b1c04ec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,     1,     2,  ..., 17182, 17183, 17184],\n",
       "        [    0,     1,     2,  ..., 17182, 17183, 17184]], device='cuda:0')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6eb95c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cpu')\n",
    "\n",
    "# cancer_type_vector = np.zeros((33,), dtype=np.float32)\n",
    "# cancer_type_vector[cancer_type] = 1\n",
    "\n",
    "# cancer_subtype_vector = np.zeros((25,), dtype=np.float32)\n",
    "# for i in CANCER_SUBTYPES[cancer_type]:\n",
    "#     cancer_subtype_vector[i] = 1\n",
    "\n",
    "# anatomical_location_vector = np.zeros((52,), dtype=np.float32)\n",
    "# anatomical_location_vector[0] = 1\n",
    "# cell_type_vector = np.zeros((10,), dtype=np.float32)\n",
    "# cell_type_vector[CELL_TYPES[cancer_type]] = 1\n",
    "\n",
    "# pt_tensor_cancer_type = torch.FloatTensor(cancer_type_vector).to(device)\n",
    "# pt_tensor_cancer_subtype = torch.FloatTensor(cancer_subtype_vector).to(device)\n",
    "# pt_tensor_anatomical_location = torch.FloatTensor(anatomical_location_vector).to(device)\n",
    "# pt_tensor_cell_type = torch.FloatTensor(cell_type_vector).to(device)\n",
    "# edge_index = torch.LongTensor(edge_index).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e826ecc2",
   "metadata": {},
   "source": [
    "## Model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5e931f85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyNet(\n",
       "  (conv1): GraphConv(1, 1)\n",
       "  (pool1): SAGPooling(GraphConv, 1, ratio=0.1, multiplier=1.0)\n",
       "  (fc1): Linear(in_features=1, out_features=1, bias=False)\n",
       "  (bn1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout1): Dropout(p=0.1, inplace=False)\n",
       "  (fc2): Linear(in_features=1024, out_features=512, bias=False)\n",
       "  (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout2): Dropout(p=0.1, inplace=False)\n",
       "  (fc3): Linear(in_features=512, out_features=1, bias=False)\n",
       "  (bn3): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout3): Dropout(p=0.1, inplace=False)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyNet(nn.Module):\n",
    "    def __init__(self, num_nodes, edge_index):\n",
    "        super(MyNet, self).__init__()\n",
    "        self.num_nodes = num_nodes\n",
    "        self.edge_index = edge_index\n",
    "        self.conv1 = GraphConv(1, 1)\n",
    "        self.pool1 = SAGPooling(1, ratio=0.1, GNN=GraphConv)\n",
    "        self.fc1 = nn.Linear(1, 1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(1)\n",
    "        self.dropout1 = nn.Dropout(0.1)\n",
    "        self.fc2 = nn.Linear(1024, 512, bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(512)\n",
    "        self.dropout2 = nn.Dropout(0.1)\n",
    "        self.fc3 = nn.Linear(512, 1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm1d(1)\n",
    "        self.dropout3 = nn.Dropout(0.1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.batches = {}\n",
    "\n",
    "    def forward(self, data):\n",
    "#         j = torch.cuda.memory_stats('cuda:0')\n",
    "#         print(j['allocated_bytes.all.current'],len(self.batches))\n",
    "        batch_size = data.shape[0]\n",
    "        x = data[:, :self.num_nodes * 1]\n",
    "        x = x.reshape(batch_size, self.num_nodes, 1)\n",
    "        batch=''\n",
    "        if True:\n",
    "            l = []\n",
    "            for i in range(batch_size):\n",
    "                l.append(Data(x=x[i], edge_index=self.edge_index))\n",
    "#             if batch_size not in self.batches:\n",
    "#                 print(x[i])\n",
    "#                 print(self.edge_index)\n",
    "            batch = Batch.from_data_list(l)\n",
    "            self.batches[batch_size] = True\n",
    "        batch = batch.to(device)\n",
    "        x = x.to(device)\n",
    "        x = x.reshape(-1, 1)\n",
    "        x = F.relu(self.conv1(x=x, edge_index=batch.edge_index))\n",
    "        x, edge_index, _, batch, perm, score = self.pool1(\n",
    "            x, batch.edge_index, None, batch.batch)\n",
    "        x = gmp(x, batch)\n",
    "        x = x.view(batch_size, -1)\n",
    "        x = self.dropout1(self.bn1(torch.relu(self.fc1(x))))\n",
    "#         x = self.dropout2(self.bn2(torch.relu(self.fc2(x))))\n",
    "#         x = self.dropout3(self.bn3(self.fc3(x)))\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "net = MyNet(len(proteins), edge_index).to(device)\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "283dacea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data, minx=None, maxx=None):\n",
    "    if minx is None:\n",
    "        minx = np.min(data)\n",
    "        maxx = np.max(data)\n",
    "    if minx == maxx:\n",
    "        return data\n",
    "    return (data - minx) / (maxx - minx)\n",
    "        \n",
    "def normalize_by_row(data):\n",
    "    for i in range(data.shape[0]):\n",
    "        data[i, :] = normalize(data[i, :])\n",
    "    return data\n",
    "\n",
    "def normalize_by_column(data):\n",
    "    for i in range(data.shape[1]):\n",
    "        data[:, i] = normalize(data[:, i])\n",
    "    return data\n",
    "\n",
    "# def normalize_by_row_and_column(data):\n",
    "#     data[:, len(proteins)*0:len(proteins)*6] = normalize_by_row(data[:, len(proteins)*0:len(proteins)*6])\n",
    "#     data[:, len(proteins)*6:len(proteins)*12] = normalize_by_column(data[:, len(proteins)*6:len(proteins)*12])\n",
    "#     return data\n",
    "\n",
    "# def normalize_by_row_and_column_and_matrix(data):\n",
    "#     data[:, len(proteins)*0:len(proteins)*6] = normalize_by_row(data[:, len(proteins)*0:len(proteins)*6])\n",
    "#     data[:, len(proteins)*6:len(proteins)*12] = normalize_by_column(data[:, len(proteins)*6:len(proteins)*12])\n",
    "#     data[:, len(proteins)*12:len(proteins)*18] = normalize(data[:, len(proteins)*12:len(proteins)*18])\n",
    "#     return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9ad59d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def normalize_train(data):\n",
    "#     minx = np.min(data)\n",
    "#     maxx = np.max(data)\n",
    "#     return (data - minx) / (maxx - minx), minx, maxx\n",
    "\n",
    "# def normalize(data, minx, maxx):\n",
    "#     return (data - minx) / (maxx - minx)\n",
    "        \n",
    "# def normalize_by_row(data):\n",
    "#     for i in range(data.shape[0]):\n",
    "#         data[i, :] = normalize(data[i, :])\n",
    "#     return data\n",
    "\n",
    "# def normalize_by_column(data):\n",
    "#     for i in range(data.shape[1]):\n",
    "#         data[:, i] = normalize(data[:, i])\n",
    "#     return data\n",
    "\n",
    "# # def normalize_by_row_and_column(data):\n",
    "# #     data[:, len(proteins)*0:len(proteins)*6] = normalize_by_row(data[:, len(proteins)*0:len(proteins)*6])\n",
    "# #     data[:, len(proteins)*6:len(proteins)*12] = normalize_by_column(data[:, len(proteins)*6:len(proteins)*12])\n",
    "# #     return data\n",
    "\n",
    "# # def normalize_by_row_and_column_and_matrix(data):\n",
    "# #     data[:, len(proteins)*0:len(proteins)*6] = normalize_by_row(data[:, len(proteins)*0:len(proteins)*6])\n",
    "# #     data[:, len(proteins)*6:len(proteins)*12] = normalize_by_column(data[:, len(proteins)*6:len(proteins)*12])\n",
    "# #     data[:, len(proteins)*12:len(proteins)*18] = normalize(data[:, len(proteins)*12:len(proteins)*18])\n",
    "# #     return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a293cddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def normalize(data):\n",
    "#     data_mean = np.mean(data)\n",
    "#     data_std = np.std(data)\n",
    "#     if data_std == 0:\n",
    "#         print('mean = ',data_mean)\n",
    "#         print('std = ',data_std)\n",
    "# #     if minx is None:\n",
    "# #         minx = np.min(data)\n",
    "# #         maxx = np.max(data)\n",
    "# #     if minx == maxx:\n",
    "# #         return data\n",
    "#         print('results = ',(data - data_mean) / (data_std))\n",
    "#     return (data - data_mean) / (data_std)\n",
    "\n",
    "\n",
    "# # def normalize(data, data_mean, data_std):\n",
    "# # #     data_mean = np.mean(data)\n",
    "# # #     data_std = np.std(data)\n",
    "# # #     if data_std == 0:\n",
    "# # #         print('mean = ',data_mean)\n",
    "# # #         print('std = ',data_std)\n",
    "# # #     if minx is None:\n",
    "# # #         minx = np.min(data)\n",
    "# # #         maxx = np.max(data)\n",
    "# # #     if minx == maxx:\n",
    "# # #         return data\n",
    "# # #         print('results = ',(data - data_mean) / (data_std))\n",
    "# #     return (data - data_mean) / (data_std)\n",
    "        \n",
    "# def normalize_by_row(data):\n",
    "#     for i in range(data.shape[0]):\n",
    "#         data[i, :] = normalize(data[i, :])\n",
    "#     return data\n",
    "\n",
    "# def normalize_by_column(data):\n",
    "#     for i in range(data.shape[1]):\n",
    "#         data[:, i] = normalize(data[:, i])\n",
    "#     return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2cd00384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_ = 0.01\n",
    "# pat_ = 10\n",
    "# norm_ = normalize\n",
    "\n",
    "# # one = 0\n",
    "# # two = 1\n",
    "# for i, cancer_type in enumerate(cancer_types):\n",
    "#     # Create a new model for each cancer type\n",
    "\n",
    "#     df = pd.read_pickle(f'preprocessing_codes/{cancer_type}.pkl')\n",
    "# #     print(df)\n",
    "\n",
    "#     dataset = np.stack(df['features'].values).reshape(len(df), -1)\n",
    "#     print(dataset.shape)\n",
    "\n",
    "#     d = []\n",
    "#     for j in range(17185):\n",
    "#         print(j)\n",
    "#         dat = dataset[:, (6*j)+2]\n",
    "#         print(dat.shape)\n",
    "#         print(dat)\n",
    "#         dat = np.log(dat + 1)\n",
    "#         print(dat)\n",
    "#         d.append(dat)\n",
    "# #         print(type(d))\n",
    "\n",
    "# #     print(dataset)\n",
    "#     print('meth_data: min = ', np.min(d), 'max = ', np.max(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4aaf493",
   "metadata": {},
   "source": [
    "## Train a model for each cancer type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8cf75e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 2.5227,\tval_loss: 1.7415\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 1.8153,\tval_loss: 1.7271\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 1.5120,\tval_loss: 1.7059\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 1.3301,\tval_loss: 1.6687\n",
      "4:\t[0s / 1s],\t\ttrain_loss: 1.2343,\tval_loss: 1.6077\n",
      "5:\t[0s / 1s],\t\ttrain_loss: 1.1444,\tval_loss: 1.4813\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 1.0578,\tval_loss: 1.3470\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 0.9734,\tval_loss: 1.1768\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 0.9572,\tval_loss: 1.2395\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 0.9728,\tval_loss: 1.3882\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 0.8613,\tval_loss: 1.1267\n",
      "11:\t[0s / 2s],\t\ttrain_loss: 0.9100,\tval_loss: 1.0933\n",
      "12:\t[0s / 2s],\t\ttrain_loss: 0.7927,\tval_loss: 1.1671\n",
      "13:\t[0s / 2s],\t\ttrain_loss: 0.8425,\tval_loss: 1.1059\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 0.8163,\tval_loss: 1.2343\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 0.7509,\tval_loss: 1.1245\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 0.8455,\tval_loss: 1.1316\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 0.7664,\tval_loss: 1.0163\n",
      "18:\t[0s / 2s],\t\ttrain_loss: 0.7459,\tval_loss: 1.1045\n",
      "19:\t[0s / 2s],\t\ttrain_loss: 0.7449,\tval_loss: 1.2327\n",
      "20:\t[0s / 2s],\t\ttrain_loss: 0.7574,\tval_loss: 1.2525\n",
      "21:\t[0s / 2s],\t\ttrain_loss: 0.7039,\tval_loss: 1.2743\n",
      "22:\t[0s / 2s],\t\ttrain_loss: 0.7431,\tval_loss: 1.1791\n",
      "23:\t[0s / 3s],\t\ttrain_loss: 0.7199,\tval_loss: 1.1841\n",
      "24:\t[0s / 3s],\t\ttrain_loss: 0.7300,\tval_loss: 1.1102\n",
      "25:\t[0s / 3s],\t\ttrain_loss: 0.7134,\tval_loss: 1.0755\n",
      "26:\t[0s / 3s],\t\ttrain_loss: 0.8154,\tval_loss: 1.1463\n",
      "27:\t[0s / 3s],\t\ttrain_loss: 0.8391,\tval_loss: 1.1797\n",
      "Concordance 0.8438522674146798\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 2.4910,\tval_loss: 1.8838\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 1.8351,\tval_loss: 1.8728\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 1.4756,\tval_loss: 1.8508\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 1.3063,\tval_loss: 1.8156\n",
      "4:\t[0s / 1s],\t\ttrain_loss: 1.1991,\tval_loss: 1.7409\n",
      "5:\t[0s / 1s],\t\ttrain_loss: 1.0855,\tval_loss: 1.6284\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 1.0091,\tval_loss: 1.4684\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 0.9973,\tval_loss: 1.3473\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 0.9770,\tval_loss: 1.2814\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 0.9305,\tval_loss: 1.3217\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 0.8278,\tval_loss: 1.3968\n",
      "11:\t[0s / 2s],\t\ttrain_loss: 0.8467,\tval_loss: 1.4494\n",
      "12:\t[0s / 2s],\t\ttrain_loss: 0.8056,\tval_loss: 1.5534\n",
      "13:\t[0s / 2s],\t\ttrain_loss: 0.8060,\tval_loss: 1.7484\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 0.8017,\tval_loss: 1.7330\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 0.7420,\tval_loss: 1.8796\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 0.8178,\tval_loss: 1.8222\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 0.7466,\tval_loss: 1.8736\n",
      "18:\t[0s / 2s],\t\ttrain_loss: 0.7269,\tval_loss: 1.9142\n",
      "Concordance 0.8258426966292135\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 2.5655,\tval_loss: 1.8814\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 1.8680,\tval_loss: 1.8643\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 1.5256,\tval_loss: 1.8341\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 1.3654,\tval_loss: 1.7799\n",
      "4:\t[0s / 1s],\t\ttrain_loss: 1.1956,\tval_loss: 1.6742\n",
      "5:\t[0s / 1s],\t\ttrain_loss: 1.1551,\tval_loss: 1.5189\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 1.0470,\tval_loss: 1.3341\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 1.0645,\tval_loss: 1.1942\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 0.9772,\tval_loss: 1.1610\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 0.9426,\tval_loss: 1.2407\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 0.8516,\tval_loss: 1.2191\n",
      "11:\t[0s / 2s],\t\ttrain_loss: 0.8286,\tval_loss: 1.3580\n",
      "12:\t[0s / 2s],\t\ttrain_loss: 0.8549,\tval_loss: 1.3377\n",
      "13:\t[0s / 2s],\t\ttrain_loss: 0.8404,\tval_loss: 1.3231\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 0.8219,\tval_loss: 1.3624\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 0.7825,\tval_loss: 1.4293\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 0.8410,\tval_loss: 1.4753\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 0.7768,\tval_loss: 1.5042\n",
      "18:\t[0s / 2s],\t\ttrain_loss: 0.7633,\tval_loss: 1.5415\n",
      "Concordance 0.8332432432432433\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 2.5526,\tval_loss: 1.8805\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 1.8417,\tval_loss: 1.8610\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 1.5335,\tval_loss: 1.8309\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 1.3119,\tval_loss: 1.7805\n",
      "4:\t[0s / 1s],\t\ttrain_loss: 1.2137,\tval_loss: 1.6669\n",
      "5:\t[0s / 1s],\t\ttrain_loss: 1.1584,\tval_loss: 1.4981\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 1.0533,\tval_loss: 1.2960\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 0.9809,\tval_loss: 1.1101\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 0.9867,\tval_loss: 1.0196\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 0.9129,\tval_loss: 1.0688\n",
      "10:\t[0s / 2s],\t\ttrain_loss: 0.7916,\tval_loss: 1.0880\n",
      "11:\t[0s / 2s],\t\ttrain_loss: 0.7766,\tval_loss: 1.1199\n",
      "12:\t[0s / 2s],\t\ttrain_loss: 0.8065,\tval_loss: 1.1259\n",
      "13:\t[0s / 2s],\t\ttrain_loss: 0.7806,\tval_loss: 1.0863\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 0.7471,\tval_loss: 1.1403\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 0.7770,\tval_loss: 1.1824\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 0.7882,\tval_loss: 1.2161\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 0.7350,\tval_loss: 1.1573\n",
      "18:\t[0s / 2s],\t\ttrain_loss: 0.7393,\tval_loss: 1.2471\n",
      "Concordance 0.8649193548387096\n",
      "0:\t[0s / 0s],\t\ttrain_loss: 2.5853,\tval_loss: 1.8839\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 1.8750,\tval_loss: 1.8709\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 1.5037,\tval_loss: 1.8387\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 1.3293,\tval_loss: 1.7909\n",
      "4:\t[0s / 1s],\t\ttrain_loss: 1.2296,\tval_loss: 1.7022\n",
      "5:\t[0s / 1s],\t\ttrain_loss: 1.1720,\tval_loss: 1.5633\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 1.0539,\tval_loss: 1.4045\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 0.9514,\tval_loss: 1.2624\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 0.8982,\tval_loss: 1.1975\n",
      "9:\t[0s / 2s],\t\ttrain_loss: 0.9063,\tval_loss: 1.1911\n",
      "10:\t[0s / 2s],\t\ttrain_loss: 0.9150,\tval_loss: 1.2838\n",
      "11:\t[0s / 2s],\t\ttrain_loss: 0.8530,\tval_loss: 1.2548\n",
      "12:\t[0s / 2s],\t\ttrain_loss: 0.7700,\tval_loss: 1.3342\n",
      "13:\t[0s / 2s],\t\ttrain_loss: 0.8389,\tval_loss: 1.3699\n",
      "14:\t[0s / 2s],\t\ttrain_loss: 0.8424,\tval_loss: 1.3617\n",
      "15:\t[0s / 2s],\t\ttrain_loss: 0.7821,\tval_loss: 1.3243\n",
      "16:\t[0s / 2s],\t\ttrain_loss: 0.7792,\tval_loss: 1.3340\n",
      "17:\t[0s / 2s],\t\ttrain_loss: 0.7344,\tval_loss: 1.3558\n",
      "18:\t[0s / 2s],\t\ttrain_loss: 0.7679,\tval_loss: 1.3746\n",
      "19:\t[0s / 2s],\t\ttrain_loss: 0.7442,\tval_loss: 1.4322\n",
      "Concordance 0.8352722196370405\n",
      "TCGA-BRCA\n",
      "lr = 0.0001\n",
      "patience = 10\n",
      "normalization = <function normalize_by_row at 0x2b43f96d48b0>\n",
      "0.8406259563525773[0.8258426966292135-0.8649193548387096]\n"
     ]
    }
   ],
   "source": [
    "# lr_ = float(sys.argv[2])\n",
    "# pat_ = int(sys.argv[3])\n",
    "# norm_ = sys.argv[4]\n",
    "\n",
    "# one = int(sys.argv[5])\n",
    "# two = int(sys.argv[6])\n",
    "\n",
    "lr_ = 0.0001\n",
    "pat_ = 10\n",
    "norm_ = normalize_by_row\n",
    "\n",
    "# one = 0\n",
    "# two = 1\n",
    "for i, cancer_type in enumerate(cancer_types):\n",
    "    # Create a new model for each cancer type\n",
    "\n",
    "    df = pd.read_pickle(f'preprocessing_codes/{cancer_type}.pkl')\n",
    "#     print(df)\n",
    "\n",
    "    dataset = np.stack(df['features'].values).reshape(len(df), -1)\n",
    "#     print(dataset.shape)\n",
    "    \n",
    "#     for j in range(17185):\n",
    "#         dataset[:, (6*j)+2] = np.log(dataset[:, (6*j)+2] + 1)\n",
    "#         dataset[:, (6*j)+3] = np.log(dataset[:, (6*j)+3] + 1)\n",
    "#         dataset[:, (6*j)+5] = np.log(dataset[:, (6*j)+5] + 14)\n",
    "\n",
    "\n",
    "    dataset = dataset[:, len(proteins)*2:len(proteins)*3]\n",
    "#     print(type(dataset))\n",
    "#     result = np.argwhere(dataset == 0)\n",
    "#     print(result)\n",
    "#     print(dataset.shape)\n",
    "#     print('meth_data: min = ', dataset.min(axis=0), 'max = ', dataset.max(axis=0))\n",
    "#     dataset = np.concatenate((dataset, dataset, dataset), axis=1)\n",
    "\n",
    "#     dataset = np.concatenate((dataset, dataset), axis=1)\n",
    "\n",
    "#                 print(dataset.shape)\n",
    "\n",
    "    in_features = dataset.shape[1]\n",
    "    labels_days = df['duration'].values\n",
    "    labels_surv = df['survival'].values\n",
    "\n",
    "    censored_index = []\n",
    "    uncensored_index = []\n",
    "    for i in range(len(dataset)):\n",
    "        if labels_surv[i] == 1:\n",
    "            censored_index.append(i)\n",
    "        else:\n",
    "            uncensored_index.append(i)\n",
    "#                 print('Censored', len(censored_index))\n",
    "#                 print('Uncensored', len(uncensored_index))\n",
    "\n",
    "    censored_index = np.array(censored_index)\n",
    "    uncensored_index = np.array(uncensored_index)\n",
    "\n",
    "#     print(dataset)\n",
    "#     print(dataset.shape)\n",
    "\n",
    "    ev_ = []\n",
    "    splits = 5\n",
    "    best_cindex = 0\n",
    "\n",
    "    num_features = 1\n",
    "    num_nodes = 17185\n",
    "\n",
    "    for fold in range(splits):\n",
    "        del net\n",
    "        torch.manual_seed(0)\n",
    "        net = MyNet(len(proteins), edge_index).to(device)\n",
    "#         net = tt.practical.MLPVanilla(in_features, [1024, 512], 1, True, lr_, output_bias=False)\n",
    "        model = CoxPH(net, tt.optim.Adam(lr_))\n",
    "        # Censored split\n",
    "        n = len(censored_index)\n",
    "        index = np.arange(n)\n",
    "        i = n // 5\n",
    "        np.random.seed(seed=0)\n",
    "        np.random.shuffle(index)\n",
    "        if fold < 4:\n",
    "            ctest_idx = index[fold * i: fold * i + i]\n",
    "            ctrain_idx = np.concatenate((index[:fold * i],index[fold * i + i:]))\n",
    "        else:\n",
    "            ctest_idx = index[fold * i:]\n",
    "            ctrain_idx = index[:fold * i]\n",
    "        ctrain_n = len(ctrain_idx)\n",
    "        cvalid_n = ctrain_n // 10\n",
    "        cvalid_idx = ctrain_idx[:cvalid_n]\n",
    "        ctrain_idx = ctrain_idx[cvalid_n:]\n",
    "\n",
    "        # Uncensored split\n",
    "        n = len(uncensored_index)\n",
    "        index = np.arange(n)\n",
    "        i = n // 5\n",
    "        np.random.seed(seed=0)\n",
    "        np.random.shuffle(index)\n",
    "        if fold < 4:\n",
    "            utest_idx = index[fold * i: fold * i + i]\n",
    "            utrain_idx = np.concatenate((index[:fold * i],index[fold * i + i:]))\n",
    "        else:\n",
    "            utest_idx = index[fold * i:]\n",
    "            utrain_idx = index[:fold * i]\n",
    "        utrain_n = len(utrain_idx)\n",
    "        uvalid_n = utrain_n // 10\n",
    "        uvalid_idx = utrain_idx[:uvalid_n]\n",
    "        utrain_idx = utrain_idx[uvalid_n:]\n",
    "\n",
    "\n",
    "        train_idx = np.concatenate((\n",
    "            censored_index[ctrain_idx], uncensored_index[utrain_idx]))\n",
    "        np.random.seed(seed=0)\n",
    "        np.random.shuffle(train_idx)\n",
    "        valid_idx = np.concatenate((\n",
    "            censored_index[cvalid_idx], uncensored_index[uvalid_idx]))\n",
    "        np.random.seed(seed=0)\n",
    "        np.random.shuffle(valid_idx)\n",
    "        test_idx = np.concatenate((\n",
    "            censored_index[ctest_idx], uncensored_index[utest_idx]))\n",
    "        np.random.seed(seed=0)\n",
    "        np.random.shuffle(test_idx)\n",
    "\n",
    "        normalize_func = norm_\n",
    "\n",
    "        train_data = dataset[train_idx]\n",
    "\n",
    "        # Normalize by rows (genes)\n",
    "        train_data = train_data.reshape(-1, num_nodes, num_features)\n",
    "\n",
    "        for i in range(num_features):\n",
    "            train_data[:, :, i] = normalize_func(train_data[:, :, i])\n",
    "#             if i <= 5:\n",
    "#                 train_data[:, :, i] = normalize_by_column(train_data[:, :, i])\n",
    "#             elif i > 5 and i <= 11:\n",
    "#                 train_data[:, :, i] = normalize_by_row(train_data[:, :, i])\n",
    "#             else:\n",
    "#                 train_data[:, :, i] = normalize(train_data[:, :, i])\n",
    "\n",
    "        train_data = train_data.reshape(-1, num_nodes * num_features)\n",
    "\n",
    "        train_labels_days = labels_days[train_idx]\n",
    "        train_labels_surv = labels_surv[train_idx]\n",
    "        train_labels = (train_labels_days, train_labels_surv)\n",
    "\n",
    "        val_data = dataset[valid_idx]\n",
    "        val_data = val_data.reshape(-1, num_nodes, num_features)\n",
    "        for i in range(num_features):\n",
    "            val_data[:, :, i] = normalize_func(val_data[:, :, i])\n",
    "#             if i <= 5:\n",
    "#                 val_data[:, :, i] = normalize_by_column(val_data[:, :, i])\n",
    "#             elif i > 5 and i <= 11:\n",
    "#                 val_data[:, :, i] = normalize_by_row(val_data[:, :, i])\n",
    "#             else:\n",
    "#                 val_data[:, :, i] = normalize(val_data[:, :, i])\n",
    "\n",
    "        val_data = val_data.reshape(-1, num_nodes * num_features)\n",
    "\n",
    "        val_labels_days = labels_days[valid_idx]\n",
    "        val_labels_surv = labels_surv[valid_idx]\n",
    "\n",
    "        test_data = dataset[test_idx]\n",
    "        test_data = test_data.reshape(-1, num_nodes, num_features)\n",
    "        for i in range(num_features):\n",
    "            test_data[:, :, i] = normalize_func(test_data[:, :, i])\n",
    "#             if i <= 5:\n",
    "#                 test_data[:, :, i] = normalize_by_column(test_data[:, :, i])\n",
    "#             elif i > 5 and i <= 11:\n",
    "#                 test_data[:, :, i] = normalize_by_row(test_data[:, :, i])\n",
    "#             else:\n",
    "#                 test_data[:, :, i] = normalize(test_data[:, :, i])\n",
    "\n",
    "        test_data = test_data.reshape(-1, num_nodes * num_features)\n",
    "\n",
    "\n",
    "        test_labels_days = labels_days[test_idx]\n",
    "        test_labels_surv = labels_surv[test_idx]\n",
    "        val_labels = (val_labels_days, val_labels_surv)\n",
    "\n",
    "#                     print(val_labels)\n",
    "#                     print('Training data', train_data.shape)\n",
    "#                     print('Validation data', val_data.shape)\n",
    "#                     print('Testing data', test_data.shape)\n",
    "        callbacks = [tt.callbacks.EarlyStopping(patience=pat_)]\n",
    "        batch_size = 32\n",
    "        epochs = 100\n",
    "        val = (val_data, val_labels)\n",
    "        log = model.fit(\n",
    "            train_data, train_labels, batch_size, epochs, callbacks, verbose=True,\n",
    "            val_data=val,\n",
    "            val_batch_size=batch_size)\n",
    "        train = train_data, train_labels\n",
    "        # Compute the evaluation measurements\n",
    "        _ = model.compute_baseline_hazards(input=train_data, target=train_labels, batch_size=batch_size)\n",
    "        surv = model.predict_surv_df(input=test_data, batch_size=batch_size)\n",
    "        ev = EvalSurv(surv, test_labels_days, test_labels_surv)\n",
    "        result = ev.concordance_td()\n",
    "        print('Concordance', result)\n",
    "        ev_.append(result)\n",
    "\n",
    "#         if result > best_cindex:\n",
    "#             best_cindex = result\n",
    "\n",
    "#             np.savetxt('test'+str(fold+1)+'.csv', test_data, delimiter=\"\\t\")\n",
    "\n",
    "#             np.savetxt('test_labels_days'+str(fold+1)+'.csv', test_labels_days, delimiter=\"\\t\")\n",
    "\n",
    "#             np.savetxt('test_labels_surv'+str(fold+1)+'.csv', test_labels_surv, delimiter=\"\\t\")\n",
    "\n",
    "    print(cancer_type)\n",
    "    print('lr = '+str(lr_))\n",
    "    print('patience = '+str(pat_))\n",
    "    print('normalization = '+str(norm_))\n",
    "    print(str(statistics.mean(ev_))+\"[\"+str(min(ev_))+\"-\"+str(max(ev_))+\"]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0439f289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, param in net.named_parameters():\n",
    "#     print(name, param.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c95327d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dev_props = [torch.cuda.get_device_properties(i) for i in [0,1]]\n",
    "# print(dev_props)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c78d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93671d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "############ When lr = 0.01 and patience = 10 ############\n",
    "# TCGA-ACC\n",
    "# 0.6407741233063947[0.5275590551181102-0.7536231884057971]\n",
    "# TCGA-BLCA\n",
    "# 0.6786161956925197[0.5468933177022274-0.7576323987538941]\n",
    "# TCGA-BRCA\n",
    "# 0.5264407521138064[0.4601997146932953-0.6046188574405279]\n",
    "# TCGA-CESC\n",
    "# 0.6089868487326608[0.4536842105263158-0.765495867768595]\n",
    "# TCGA-CHOL\n",
    "# 0.9375[0.6875-1.0]\n",
    "# TCGA-COAD\n",
    "# 0.5416567327522879[0.45670460168233545-0.6013229104028863]\n",
    "# TCGA-DLBC\n",
    "# 0.6031457431457431[0.4222222222222222-0.8571428571428571]\n",
    "# TCGA-ESCA\n",
    "# 0.6415943578057707[0.5074626865671642-0.7283950617283951]\n",
    "# TCGA-GBM\n",
    "# 0.699952665470347[0.5194805194805194-0.7992565055762082]\n",
    "# TCGA-HNSC\n",
    "# 0.7737905917605848[0.6917922948073701-0.83729216152019]\n",
    "# TCGA-KICH\n",
    "# 0.6480249817695936[0.5675675675675675-0.775]\n",
    "# TCGA-KIRC\n",
    "# 0.6073085521679165[0.5231447465099192-0.7541371158392435]\n",
    "# TCGA-KIRP\n",
    "# 0.6151314344759501[0.48286604361370716-0.7481559536354057]\n",
    "# TCGA-LAML\n",
    "# 0.8832229258328248[0.8064516129032258-0.9448818897637795]\n",
    "# TCGA-LGG\n",
    "# 0.6443044653183997[0.5934823091247672-0.6978891820580475]\n",
    "# TCGA-LIHC\n",
    "# 0.6609286641468511[0.58-0.7258215962441315]\n",
    "# TCGA-LUAD\n",
    "# 0.6784523994943508[0.6162207357859532-0.7453441295546559]\n",
    "# TCGA-LUSC\n",
    "# 0.6422733977564488[0.6197286395306197-0.665785997357992]\n",
    "# TCGA-MESO\n",
    "# 0.9577476896625833[0.8701298701298701-1.0]\n",
    "# TCGA-OV\n",
    "# 0.8360278828043031[0.7760635811126695-0.8740636704119851]\n",
    "# TCGA-PAAD\n",
    "# 0.6975654816040123[0.5770925110132159-0.8082901554404145]\n",
    "# TCGA-PCPG\n",
    "# 0.5456235251701532[0.4766355140186916-0.6860759493670886]\n",
    "# TCGA-PRAD\n",
    "# 0.5008283644794941[0.44887278582930756-0.5632447296058661]\n",
    "# TCGA-READ\n",
    "# 0.5334667030656595[0.39925373134328357-0.6296296296296297]\n",
    "# TCGA-SARC\n",
    "# 0.6346771780431426[0.4776978417266187-0.804920913884007]\n",
    "# TCGA-SKCM\n",
    "# 0.7337072562089696[0.6738648947951273-0.8325867861142218]\n",
    "# TCGA-STAD\n",
    "# 0.7194974133738123[0.5998831775700935-0.7921166306695464]\n",
    "# TCGA-TGCT\n",
    "# 0.6178811566240728[0.5053191489361702-0.7293577981651376]\n",
    "# TCGA-THCA\n",
    "# 0.5299605129796416[0.4819364161849711-0.5824175824175825]\n",
    "# TCGA-THYM\n",
    "# 0.5782367078355151[0.44-0.7461538461538462]\n",
    "# TCGA-UCEC\n",
    "# 0.6120250711669957[0.5395114942528736-0.6941176470588235]\n",
    "# TCGA-UCS\n",
    "# 0.7368138376632117[0.6086956521739131-0.8823529411764706]\n",
    "# TCGA-UVM\n",
    "# 0.681177536231884[0.5625-0.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff47c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ############ When lr = 0.0001 and patience = 20 ############\n",
    "# TCGA-ACC\n",
    "# 0.6882712329658379[0.6376811594202898-0.7971014492753623]\n",
    "# TCGA-BLCA\n",
    "# 0.5890027508380132[0.5258245177349098-0.6554517133956387]\n",
    "# TCGA-BRCA\n",
    "# 0.527074110092128[0.4387621540762902-0.5636395207501302]\n",
    "# TCGA-CESC\n",
    "# 0.589973099622829[0.540506329113924-0.712468193384224]\n",
    "# TCGA-CHOL\n",
    "# 0.5555555555555556[0.0-1.0]\n",
    "# TCGA-COAD\n",
    "# 0.5459434785976518[0.4670074349442379-0.6057171020206998]\n",
    "# TCGA-DLBC\n",
    "# 0.4984848484848485[0.25-0.9090909090909091]\n",
    "# TCGA-ESCA\n",
    "# 0.4986375992316221[0.4444444444444444-0.6232394366197183]\n",
    "# TCGA-GBM\n",
    "# 0.6782654586317148[0.6045627376425855-0.7610294117647058]\n",
    "# TCGA-HNSC\n",
    "# 0.6791943114955646[0.6413373860182371-0.7038001041124414]\n",
    "# TCGA-KICH\n",
    "# 0.6620646816259077[0.41304347826086957-0.875]\n",
    "# TCGA-KIRC\n",
    "# 0.6227483865794052[0.5598824393828068-0.671559633027523]\n",
    "# TCGA-KIRP\n",
    "# 0.4827822329411887[0.4236453201970443-0.598937583001328]\n",
    "# TCGA-LAML\n",
    "# 0.8323271507079413[0.7612903225806451-0.8620689655172413]\n",
    "# TCGA-LGG\n",
    "# 0.526960884964874[0.4564932225623087-0.6001838235294118]\n",
    "# TCGA-LIHC\n",
    "# 0.5697073188251252[0.5463623395149786-0.6169014084507042]\n",
    "# TCGA-LUAD\n",
    "# 0.5905062967495905[0.5593645484949833-0.6244131455399061]\n",
    "# TCGA-LUSC\n",
    "# 0.5712931058147199[0.5031739314430809-0.6450902686041391]\n",
    "# TCGA-MESO\n",
    "# 0.7864640324214792[0.6818181818181818-0.8181818181818182]\n",
    "# TCGA-OV\n",
    "# 0.703446385128956[0.636109818520242-0.7775675675675676]\n",
    "# TCGA-PAAD\n",
    "# 0.6147314269758151[0.5191082802547771-0.7631578947368421]\n",
    "# TCGA-PCPG\n",
    "# 0.5002996900088952[0.3911764705882353-0.6241830065359477]\n",
    "# TCGA-PRAD\n",
    "# 0.4923555066084578[0.4510086455331412-0.5229147571035747]\n",
    "# TCGA-READ\n",
    "# 0.5850391331932935[0.5111940298507462-0.6925925925925925]\n",
    "# TCGA-SARC\n",
    "# 0.6605232504700553[0.6114982578397212-0.735973597359736]\n",
    "# TCGA-SKCM\n",
    "# 0.6151867750657317[0.5194877505567929-0.7043673012318029]\n",
    "# TCGA-STAD\n",
    "# 0.6225493511385155[0.5163551401869159-0.7319899244332494]\n",
    "# TCGA-TGCT\n",
    "# 0.584073905256942[0.5478723404255319-0.6246851385390428]\n",
    "# TCGA-THCA\n",
    "# 0.4994043519200372[0.3592269799166351-0.6006351726875744]\n",
    "# TCGA-THYM\n",
    "# 0.5762585579099554[0.424-0.8153846153846154]\n",
    "# TCGA-UCEC\n",
    "# 0.5615907273146579[0.5028735632183908-0.6479799561540871]\n",
    "# TCGA-UCS\n",
    "# 0.790509585985424[0.6521739130434783-0.9565217391304348]\n",
    "# TCGA-UVM\n",
    "# 0.6054166666666666[0.525-0.7]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
